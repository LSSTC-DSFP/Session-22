{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Enabled Visualization\n",
        "## Variational Autoencoders and Latent Space Representations of Astronomical Data\n",
        "### Bryan Scott, CIERA | Northwestern\n",
        "\n",
        "This tutorial but has been adapted here from one by Charles Kenneth Fisher and Raghav Kansal. That tutorial was itself an adaptation of a great introduction to VAEs by Louis Tiao. The solutions notebook will include links to this heritage.\n",
        "\n",
        "This example should be taken mostly as a framework/outline of how to build an autoencoder. In a research setting, careful choices about loss functions and architecture should be investigated. Recent work, for example, on (non-variational) autoencoders has shown the importance of accounting for *redshift invariance* in galaxy spectra. Since the focus here is getting some practice with ML enabled visualization, these deeper questions are left for a future version of this tutorial.\n",
        "\n"
      ],
      "metadata": {
        "id": "k-7K8HpJSO-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install specific version of tensorflow\n",
        "(to simplify with some syntax changes in more recent versions)"
      ],
      "metadata": {
        "id": "v7uQi-TfSnQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.14.0"
      ],
      "metadata": {
        "id": "77MTka4CMC2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading required libraries, numpy, matplotlib, and a scipy.norm\n",
        "(which we will use for visualizing a latent space with assumed gaussian distribution)\n",
        "\n",
        "This tutorial is in keras which is a convenient library for abstracting Deep Learning code and making things more readable. The model itself will be trained in tensorflow. In Session 19, we used pytorch to teach Deep Learning, and it would be nice to convert this tutorial to pytorch (hack day project?)."
      ],
      "metadata": {
        "id": "uFayNNcJSvev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBppCcOKLHrq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.layers import Input, InputLayer, Dense, Lambda, Layer, Add, Multiply\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow.compat.v1 as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some lines to read in the Galaxy Zoo 2 Hubble Space Telescope Images. These have been downsized to 128x128 to keep this within colab's RAM limits. 14000 total images are provided in the GZ2 HST dataset, of which we will train on ~8000. You should play around with the number of images to train on."
      ],
      "metadata": {
        "id": "aZL9swt3TR_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading goes here"
      ],
      "metadata": {
        "id": "uZynjq9bMgoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1: Look at the last layer of the model to answer the following question - why do the HST images get divided by 255.0?"
      ],
      "metadata": {
        "id": "Spvf95nLTpxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train) / 255.0\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "ecUCcNaFLTTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2: Visualize a few of the input images."
      ],
      "metadata": {
        "id": "KDCuXCpWUAhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code goes here"
      ],
      "metadata": {
        "id": "20XA7TbYUGnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell defines some dimensions we choose and gets the shape of the data for later required reshapes."
      ],
      "metadata": {
        "id": "d6ct_R8qURC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find dimensions of input images\n",
        "img_rows, img_cols, img_chns = x_train.shape[1:]\n",
        "\n",
        "# Specify hyperparameters\n",
        "original_dim = img_rows * img_cols\n",
        "intermediate_dim = 256\n",
        "latent_dim = 2\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "epsilon_std = 1.0"
      ],
      "metadata": {
        "id": "VBPtcQ1eLb2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell defines the loss function. There are two terms, the binary cross entropy between the inputs and outputs, and a KL divergence layer which 'regularizes' such that the distribution of latent space vectors approximates a Gaussian."
      ],
      "metadata": {
        "id": "lYApp_KAUZM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nll(y_true, y_pred):\n",
        "    \"\"\"Negative log likelihood (Bernoulli).\"\"\"\n",
        "\n",
        "    # keras.losses.binary_crossentropy gives the mean\n",
        "    # over the last axis. we require the sum\n",
        "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
        "\n",
        "\n",
        "class KLDivergenceLayer(Layer):\n",
        "    \"\"\"Identity transform layer that adds KL divergence\n",
        "    to the final model loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.is_placeholder = True\n",
        "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mu, log_var = inputs\n",
        "\n",
        "        kl_batch = -0.5 * K.sum(1 + log_var - K.square(mu) - K.exp(log_var), axis=-1)\n",
        "\n",
        "        self.add_loss(K.mean(kl_batch))\n",
        "\n",
        "        return inputs"
      ],
      "metadata": {
        "id": "8Eg8RBUeLgLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This defines the encoder and decoder layers. The lines involving z are telling the model that the latent space distribution should be a Gaussian, while the lines with eps are the 'reparameterization trick' that we'll cover in a future session.\n",
        "\n",
        "The encoder takes data and maps it to a distribution of latent space vectors. The decoder takes vectors on the latent space and maps them back to the data.\n",
        "\n",
        "Problem 3: Make sure you understand (roughly) what each line here does, and check that you know why each layer has the dimensions that they do."
      ],
      "metadata": {
        "id": "8cMvMKaaUxYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "\n",
        "x = Input(shape=(original_dim,))\n",
        "h = Dense(intermediate_dim, activation=\"relu\")(x)\n",
        "\n",
        "z_mu = Dense(latent_dim)(h)\n",
        "z_log_var = Dense(latent_dim)(h)\n",
        "\n",
        "z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n",
        "\n",
        "# Reparametrization trick\n",
        "z_sigma = Lambda(lambda t: K.exp(0.5 * t))(z_log_var)\n",
        "\n",
        "eps = Input(tensor=K.random_normal(shape=(K.shape(x)[0], latent_dim))) # note that this line changes in newer keras/tensorflow versions\n",
        "\n",
        "z_eps = Multiply()([z_sigma, eps])\n",
        "z = Add()([z_mu, z_eps])\n",
        "\n",
        "# This defines the Encoder which takes noise and input and outputs\n",
        "# the latent variable z\n",
        "encoder = Model(inputs=[x, eps], outputs=z)\n",
        "\n",
        "# Decoder is MLP specified as single Keras Sequential Layer\n",
        "decoder = Sequential(\n",
        "    [\n",
        "        Dense(intermediate_dim, input_dim=latent_dim, activation=\"relu\"),\n",
        "        Dense(original_dim, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "x_pred = decoder(z)"
      ],
      "metadata": {
        "id": "TZ26Ci4fLjs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Variational Autoencoder"
      ],
      "metadata": {
        "id": "H5-FaPbQVeFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vae = Model(inputs=[x, eps], outputs=x_pred, name=\"vae\")\n",
        "vae.compile(optimizer=\"rmsprop\", loss=nll)\n",
        "vae.summary()"
      ],
      "metadata": {
        "id": "WW5hJ6_KLmVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ],
      "metadata": {
        "id": "9zlfXGlMVhkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1, original_dim)\n",
        "\n",
        "hist = vae.fit(\n",
        "    x_train,\n",
        "    x_train,\n",
        "    shuffle=True,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size)"
      ],
      "metadata": {
        "id": "e-OKwTqdLopq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 4: Plot the latent space vectors. Since the latent space dimension is 2D, these will just be points in a plane. This is dangerous - since it may not, and we are pattern seeking creatures who find them when none exist - but our goal is to see if the latent space has some clear structure we can interpret."
      ],
      "metadata": {
        "id": "Ys43yPrcWB5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_encoded = encoder.predict(x_train, batch_size=batch_size)\n",
        "plt.figure()\n",
        "plt.scatter(x_train_encoded[:, 0], x_train_encoded[:, 1])\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z-E_foYiLsIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 5: Now, create a grid of images where each image is a uniform sample from the latent space. In other words, uniformly sample vectors on the 2D latent space and use these as inputs to the decoder, which will give you an image back. The grid you produce here should have the same structure as the latent space."
      ],
      "metadata": {
        "id": "xsJO7QrkVpjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # display a 2D manifold of the images\n",
        "n = 5  # figure with 15x15 images\n",
        "quantile_min = 0.01\n",
        "quantile_max = 0.99\n",
        "\n",
        "# Linear Sampling\n",
        "# we will sample n points within [-15, 15] standard deviations\n",
        "z1_u =\n",
        "z2_u =\n",
        "z_grid = np.dstack()\n",
        "\n",
        "x_pred_grid = decoder.predict().reshape() #hint, should take latent space vectors and reshape them to make a figure grid\n",
        "\n",
        "\n",
        "ax.set_xlabel(\"$z_1$\")\n",
        "ax.set_ylabel(\"$z_2$\")\n",
        "ax.set_title(\"Uniform\")"
      ],
      "metadata": {
        "id": "CwpNkh_4Lw_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 5: We assumed that the latent space was a Gaussian. So instead of sampling uniformly, now sample from latent space such that the probability of selecting each point is given by the gaussian distribution on the latent space. Visualize these."
      ],
      "metadata": {
        "id": "XkfNeHMCWMal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse CDF sampling\n",
        "# hint, same as before, but you might find norm.ppf helpful.\n",
        "# You should have a sense of why specifically this function is helpful\n",
        "z1 =\n",
        "z2 =\n",
        "z_grid2 = np.dstack()\n",
        "\n",
        "x_pred_grid2 = decoder.predict().reshape()\n",
        "\n",
        "\n",
        "\n",
        "ax.set_xlabel(\"$z_1$\")\n",
        "ax.set_ylabel(\"$z_2$\")\n",
        "ax.set_title(\"Inverse CDF\")"
      ],
      "metadata": {
        "id": "UbIHACSSLz8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 6: After completing the visualization steps above, change the latent space dimension to N > 3. Use a dimensionality reduction or clustering technique to visualize the latent space.\n",
        "\n",
        "How stable is the latent space representation that you have learned? Does it change if the image dimensions change? What about your interpretation?"
      ],
      "metadata": {
        "id": "_JvQZ36qWlGu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DLVdA5nlW03_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}